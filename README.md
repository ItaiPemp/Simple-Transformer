# Simple-Transformer
<img width="407" alt="image" src="https://github.com/ItaiPemp/Simple-Transformer/assets/102918201/a83ff4fc-ba83-4428-9798-5d5592f84589">

# overview
This repository includes a simple implementation of the original transformer architecture. Additionally, it features a decoder-only transformer that was trained on Shakespearean text. Using a straightforward character-level tokenization, the model can generate Shakespearean-themed text.


## Citation
- ["Attention is All You Need"](https://arxiv.org/abs/1706.03762) by Vaswani et al.

```bibtex
@inproceedings{vaswani2017attention,
  title={Attention is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, ≈Åukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5998--6008},
  year={2017}
}
